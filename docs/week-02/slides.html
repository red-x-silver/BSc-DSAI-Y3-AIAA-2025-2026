
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <title>Artificial Intelligence and Advanced Analytics 02</title>
  <!-- This whole presentation was made with Big: https://github.com/tmcw/big -->
  
  <link href="../big/big.css" rel="stylesheet" type="text/css" />
  <script src="../big/big.js"></script>
  <link href="../big/themes/lightWhite.css" rel="stylesheet" type="text/css" />

  <!-- Favicon link below, via https://emojitofavicon.com -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%2210 0 100 100%22><text y=%22.90em%22 font-size=%2290%22>üç¥</text></svg>"></link>
  
  <style>
    body {
      background-color: #EDDD6E;
      font-family: -apple-system, BlinkMacSystemFont, avenir next, avenir, helvetica neue, helvetica, Ubuntu, roboto, noto, segoe ui, arial, sans-serif;
      /* font-weight: 700;*/
      margin: 0;
      padding: 0;
      font-style: normal;
      font-size: 21px;
    }
  </style>
  
</head>
<body>
  <div>
    AIAA
    <br />
    Lecture 02
    <br />
    Neural networks quick recap + AI in Computer Vision part 1  
  </div>
    
  <div>Welcome üë©‚Äçüé§üßë‚Äçüé§üë®‚Äçüé§</div>
  
  <div> By the end of this lecture, we'll have learnt about:
  
     <br /> The theoretical: 
     <br /> - Introduction to the unit
     <br /> - Quick revisions on data modalities and neural networks
     <br />  - AI applications in Computer Vision part 01
     <br />  - - Image classification, Object detection, Image segmentation, Keypoint detection
     <br /> The practical: 
     <br /> - test(inference) models on hugging face
     <br /> - test(inference) models from Tensorflow.js
    <br /> - test(inference) YOLOv11 on your laptop / google colab notebook
  
  </div>
  
  <div> First of all, don't forget to confirm your attendence on <a href="https://www.arts.ac.uk/study-at-ual/course-regulations/attendance-policy/attendance-monitoring"> SEAtS App!  </a></div>

   <div> What is this unit about? </div>
  
  <div> AI deployment in professional ecosystems, with a wide range of domains including: </div>
  
  <div> 
    - Large language model (week 01)
    <br /> 
    - AI in Computer Vision (week 02, 03)
    <br /> 
    - AI in audio and music (week 04, 05)
    <br /> 
    - AI in 3D and gaming (week 06, 07)
    <br /> 
    -AI in affective computing (week 08)
    <br /> 
    - AI in recommender systems (week 09)  
    <br /> 
    - Multi-modal AI (week 10)
    <br /> 
    - Explainable AI (week 11)
    
  </div>

    <div> How to get support?
    <br /> - Reach out to me and Kayal via Slack or Email 
     <br /> - The fun of being an autodidact: <a href="https://huggingface.co/"> Hugging Face</a>, <a href="https://www.arts.ac.uk/students/library-services">UAL Library</a>, 
    <a href="https://chat.openai.com/">ChatGPT but be careful</a>, resources listed on our <a href="https://moodle.arts.ac.uk/course/view.php?id=87940">Moodle Page</a>
  
  </div>

    <div> This is a very practical and fun unit, getting you ready for your final thesis project. 
     <br /> 
     - We'll play around with a LOT of pre-trained and ready-to-use models during each lecture. 
     <br /> 
     - We expect you to spend 16 hours to do the readings, hands-on practice & homework on this unit outside the standard lecture time.
      <br />  
      - It will be a very rewarding experience if you put in the effort. We will support you all the way. 
  
  </div>
  
  
  <div> any questions so far? </div>

  <div>     
       About me
                  <br /> 
                
                <a href="xiaowan-yi.com">xiaowan yi</a>: sh-iao one e

                <br />
                she/they
                <br />
                
                - I was born in Chengdu, China. My city is famous for panda üêº, taoism ‚òØÔ∏è and spicy food üå∂Ô∏è.
                     <br /> 
                - I live in Surrey Quays now.
                 <br /> 
                
- I'm completing my PhD research in AI&Music at QMUL.
  <br /> 
- I make sound and you can find some of my works <a href="https://vimeo.com/user65401583">here</a>.
    <br /> 
- I play drums ü•Å for electronic and groovy music.
  </div>



  <div> Recap on data modalities</div>

  <div> 
    Data modalities
     <br />    
    Information that we can gather from the world and store in digital systems as "data", are mainly from four modalities:
      <br />   
    - Image (picture, video)
      <br />   
    - Text (written language)
      <br />   
    - Audio (music, speech)
      <br />   
    - Tabular(this week's weather in degree celsius, everyone's birthday in this class, sensor data, etc.)
      <br />  
      Can you think of any information that is not from the four categories?
  </div>
  
  
  <div> 
    Data modalities
     <br />    
    - Each data modality has its own characteristics and challenges for representation, processing and analysis.
      <br />
     - We structure our unit syllabus based on the different data modalities, each week focusing on one modality (with a few exceptions).
      <br />
  </div>

   <div> Recap on neural networks</div>

    <div> 
    Recap on neural networks
    <br />    
    - Architectures
      <br />
    - How to train a neural network?
      <br />
    - How to inference a neural network?
    <br />
    Recommended reading: 
     <br />
   - - <a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> by Michael Nielsen
     <br />
    - -  <a href="https://www.deeplearningbook.org/">Deep Learning Book</a> by Ian Goodfellow, Yoshua Bengio and Aaron Courville
  </div>

        <div> 
    Neural network architecture
    <br />    
    - neural network comprises of layers
      <br />
    - there are different types of layers (fully connected, convolutional, recurrent, transformer, etc.)
      <br />
    - Here is a list of layers by <a href="https://docs.pytorch.org/docs/stable/nn.html">Pytorch</a> (have you used Pytorch before?)
    </div>



        <div> 
    Questions for checking understanding
    <br />    
    - What is a MLP?
      <br />
    - What is a CNN?
      <br />
    - What is a RNN?
      <br />
    - What is a Transformer?
    </div>

      <div> 
   How to inference a neural network? The process:
    <br />  - - feed input data into the model and get the output from the model
      <br /> - - also called the forward pass
     <br /> - - also called 'testing' or 'evaluation'
      <br /> - - inference does not involve backpropagation
      <br /> !No need to hard memorise!
 </div>

       <div> 
     How to train a neural network? The process:
    <br />  - - feed input data into the model and get the output from the model
      <br /> - - compare the model output with the ground truth and calculate the loss
      <br /> - - use backpropagation to update the model parameters
      <br /> - - repeat the above steps until the model converges
      <br /> - - this whole process is called training
      <br /> - - training involves both forward pass and backward pass

 </div>

        <div> 
 
     How to train a neural network? The dataset and splits:
      <br /> - - training is done on a training dataset
      <br /> - - the trained model is then evaluated on a validation dataset and/or a test dataset
      <br /> - - the trained model is then deployed for inference on new data
 </div>

        <div> 
  How to train a neural network? The hyperparameters: 

      <br /> - - training is done using an optimisation algorithm (e.g. SGD, Adam, etc.)
      <br /> - - training is done using a loss function (e.g. cross-entropy, MSE, etc.)
      <br /> - - training is done using a learning rate (e.g. 0.001, 0.01, etc.)
      <br /> - - training is done using a batch size (e.g. 32, 64, etc.)
      <br /> - - training is done using a number of epochs (e.g. 10, 20, etc.)
      <br /> - - training is done using a validation set to monitor overfitting
      <br /> - - training is done using regularisation techniques (e.g. dropout, weight decay, etc.)
 <br /> !No need to hard memorise!
    </div>


            <div> 
 
     Terminologies:
      <br /> Pre-trained
      <br /> - - means a ready-to-use model
      <br /> - - means a model that has been trained on a dataset (often large) and can be fine-tuned on a smaller dataset for a specific task in the future
      <br /> Fine-tuning 
      <br /> - - means further training a pre-trained model on a smaller dataset for a specific task
      <br /> - - means updating the model parameters using backpropagation on the smaller dataset
      <br /> - - means the model is adapted to the specific task and the dataset
      <br /> - - means the model is not trained from scratch
      <br /> Transfer learning
      <br /> - - means using a pre-trained model for a different but related task
      <br /> - - also means the model is not trained from scratch
      <br /> - - fine-tuning is a special case of transfer learning
      <br /> - - transfer learning can be done without fine-tuning (e.g. using the pre-trained model as a feature extractor and adding new layers to the model for training on the new task)
    </div>
 </div>

        <div> 

    Recommended reading: 
     <br />
   - - <a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> by Michael Nielsen
     <br />
    - -  <a href="https://www.deeplearningbook.org/">Deep Learning Book</a> by Ian Goodfellow, Yoshua Bengio and Aaron Courville
  </div>


      <div> AI in Computer Vision part 01 üëÅÔ∏è</div>


      <div> Computer Vision: a field of AI that teaches computers to "see" and interpret the visual world from images and videos, derive meaningful information from them. </div>

 


      <div> 
    üëÅÔ∏è Basic computer vision tasks: 
     <br />    
    - Image classification
      <br />
    - Object detection
      <br />
    - Image segmentation
      <br />
    - Keypoints detection
  </div>

        <div> 
    üëÅÔ∏è Basic computer vision tasks, characterised by the model (neural network) outputs:
     <br />    
    - Image classification: outputs a class label.
      <br />
    - Object detection: outputs bounding boxes and class labels.
      <br />
    - Image segmentation: outputs pixel-wise masks and class labels.
      <br />
    - Keypoints detection: outputs keypoints and class labels.
  </div>


         <div> How about the input? How does a model "see" an image? 
           <br />
          - Model "sees" an image as numbers!
           <br />  
          - Digital images are made of pixels.
          <br />
          - Each pixel in the image is represented by a number (or a set of numbers for color images).  
        </div>  

  <div> 
    üëÅÔ∏è Images represented by numbers:
     <br />  
    - Two numbers for its width and height (how many pixels).
    <br />  
    e.g. 3840 x 2160 for 4K resolution        
    <br />      
    - Sometimes another number for how many color channels there are.
   <br />      
    e.g. 256 x 256 x 3 for an RGB color image
  </div>
  
  <div class='layout' style='grid-template-rows:55% 45%;'>
  <img src='https://cdn.glitch.global/0e13d0b6-6ebc-4330-9873-db7826d23957/pixels.png?v=1696434561327'/>
  <div>Here is one way to numberify digital images:
     <br />  
  - Three numbers for each pixel representing the RGB values in color images
     <br />     
  - One number for each pixel representing the greyscale value in grey images </div>
  </div>

          <div> 
    üëÅÔ∏è Let's go to <a href="https://huggingface.co/">Hugging Face</a> (have you explored this platform before?) for web-based, ready-to-use models for:
     <br />    
    - Image classification
      <br />
    - Object detection
      <br />
    - Image segmentation
      <br />
    - Keypoints detection
  </div>

           <div> 
    üëÅÔ∏è Let's go to <a href="https://github.com/tensorflow/tfjs-models/tree/master">Tensorflow.js github repo</a> (have you explored this platform before?) for models and demos for:
     <br />    
    - Image classification
      <br />
    - Object detection
      <br />
    - Image segmentation
      <br />
    - Hand/Pose/Facial keypoints detection
  </div>

  

    <div> Check out computer vision models adopted by <a href="  https://developer.apple.com/machine-learning/models/">Apple Core ML</a> 
     <br /> These are the industry standard models.
 <br /> Practice:
      <br /> - Pick one model that can do one of the four basic computer vision tasks, and research on:
      <br /> - - What is the model name?
      <br /> - - Is there a public code repository e.g. github?
      <br /> - - What dataset is the model trained on?
      <br /> - - What is the size of the model?
      <br /> - - What is the model performance like, on what evaluation metrics?
    </div>


      <div> 
    YOLO on <a href="https://github.com/ultralytics/ultralytics">Ultralytics</a> 
     <br />    
    - <a href="https://docs.ultralytics.com/tasks/">What are the tasks that YOLOv11 can do?</a>  
      <br />
    - What are the outputs of YOLOv11 for each of the tasks?

  </div>

      <div> 
    YOLO on <a href="https://github.com/ultralytics/ultralytics">Ultralytics</a> 
     <br />    
    Hands-on: 
      <br />
    - Inference YOLOv11 on the google colab notebook.
      <br />
    - Inference YOLOv11 on your laptop.
    <br />
    Keep a cool dev note of:
      <br />
    - - Error messages you have encountered
    <br />
    - - Words that you don't understand
    <br /> 
    - - Things that you find interesting
  </div>

        <div> 
    YOLO on <a href="https://github.com/ultralytics/ultralytics">Ultralytics</a> 
     <br />    
    Homework:
      <br />
    - Inference YOLOv11 on your laptop for all 4 tasks.
    <br />
    - Inference YOLOv11 on the workstation.
    <br />
    - [Optional but highly rewarding] Fine tuning YOLOv11 on the workstation, using a custom dataset.
  </div>

          <div> 
    What we have learnt today:
      <br />
    - Recap on data modalities and neural networks
    <br />
    - Image classification, Object detection, Image segmentation, Keypoint detection
    <br />
    - Played around with pre-trained computer vision models on Hugging Face, Tensorflow.js and Apple Core ML
    <br />
    - An example of industry-level computer vision model: YOLOv11
  </div>
  
  <div> 
    We'll see you next Monday same time and same place!
  </div>
  
</body>
</html>
