<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <title>Artificial Intelligence and Advanced Analytics 03</title>
  <!-- This whole presentation was made with Big: https://github.com/tmcw/big -->
  
  <link href="../big/big.css" rel="stylesheet" type="text/css" />
  <script src="../big/big.js"></script>
  <link href="../big/themes/lightWhite.css" rel="stylesheet" type="text/css" />

  <!-- Favicon link below, via https://emojitofavicon.com -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%2210 0 100 100%22><text y=%22.90em%22 font-size=%2290%22>ğŸ´</text></svg>"></link>
  
  <style>
    body {
      background-color: #EDDD6E;
      font-family: -apple-system, BlinkMacSystemFont, avenir next, avenir, helvetica neue, helvetica, Ubuntu, roboto, noto, segoe ui, arial, sans-serif;
      /* font-weight: 700;*/
      margin: 0;
      padding: 0;
      font-style: normal;
      font-size: 21px;
    }
  </style>
  
</head>
<body>
  <div>
    AIAAğŸ‘
    <br />
    Lecture 04
    <br />
    AI applications in the audio domain ğŸ‘ï¸  
  </div>
    
  <div>Welcome ğŸ‘©â€ğŸ¤ğŸ§‘â€ğŸ¤ğŸ‘¨â€ğŸ¤</div>
  
  <div> By the end of this lecture, we'll have learnt about:
  
     <br /> The theoretical: 
     <br /> - Introduction to speech-to-text models
     <br /> - Introduction to text-to-speech synthesis models
     <br />  - Introduction to voice clone applications
    
     <br /> The practical: 
     <br /> - build a Web App that uses OpenAI's Whisper API
  
  </div>
  
  <div> First of all, don't forget to confirm your attendence on <a href="https://www.arts.ac.uk/study-at-ual/course-regulations/attendance-policy/attendance-monitoring"> SEAtS App!  </a></div>

  <div>
  <h2>ğŸ¤SPEECH!ğŸ¤</h2>
  <p>Speech is one of the most natural human communication forms.</p>
  <p>It carries linguistic content, emotion, and identity etc.</p>
  <p>AI application in speech aims to make computers understand and produce human speech naturally.</p>
</div>

  

  <div> 
    Homework:
   <br />
    - Inference <a href="https://github.com/NVlabs/stylegan3">StyleGAN3</a> or <a href="https://github.com/NVlabs/stylegan2">StyleGAN2</a> (choose one or more pre-trained models from the repos) on your laptop or workstation
   <br />
    - Train a <a href="https://github.com/red-x-silver/PokeGAN">Pokemon GAN</a> on your laptop or the workstation. Show me your pokemons!
   <br />
     - Inference a stable diffusion model from your laptop with the <a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/overview">hugging face library for stable diffusions</a>, it is SO HANDY!
    <br />
    - SEND ME your dev note by next Monday!
    <br />
    - [Optional but highly rewarding] Train a StyleGANX on the workstation, using a custom dataset (think of an applicatin that is interesting to you!).
  </div>

   <div> 
    ğŸ•¶ï¸ What we have learnt today:
      <br />
   Three types of model family for generating images:
    - VAE
    <br />
    - GAN
    <br />
    - Diffusion
    <br />
    - Inspect and inference examples of industry-level generative model: StyleGAN, Stable Diffusion
  </div>
  
  <div> 
    We'll see you next Monday same time and same place!
  </div>
  
</body>
</html>
